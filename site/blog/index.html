<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Blog - Paul Smith</title>
    <meta name="description" content="Paul Smith, programmer, EveryBlock co-founder">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=PT+Sans:regular,bold|Inconsolata|PT+Serif:regular,bold,italic">
    <!--[if gte IE 7]><!-->
    <link rel="stylesheet" media="screen, projection" href="/css/base.css" type="text/css">
    <!-- <![endif]-->
    <link rel="alternate" href="/atom.xml" type="application/atom+xml">
    <link rel="openid.server" href="http://www.myopenid.com/server/">
    <link rel="openid.delegate" href="http://pauladamsmith.myopenid.com/">
    <meta name="verify-v1" content="JGWpUVGeSZp407VK35oscFKsTMIEalzD8cTIBcScWNQ=">
    
</head>
<body class="blog">
    <header>
        <h1><a href="/">Paul Smith</a></h1>
        <nav>
            <ul>
                <li><a href="/about.html">About</a></li>
                <li><a href="/blog/">Blog</a></li>
                <li><a href="/articles/">Articles</a></li>
                <li><a href="/projects.html">Projects</a></li>
            </ul>
        </nav>
    </header>
    <div id="main">
        
<article class="post">
  <header>
    <h1><a href="/blog/2013/01/dnc_voter_reg_foss.html" title="Permalink to this post">Democratic Party’s voter registration app is now free and open-source software</a></h1>
    <time datetime="2013-01-28" pubdate>January 28, 2013</time>
  </header>
  <p>We (the <a href="http://democrats.org/">DNC</a>) have <a href="https://github.com/democrats/voter-registration/issues/12#issuecomment-12804999">relicensed the Democratic Party’s voter registration
application</a> under a standard MIT license, and accompanied the source
code with an advisory notice regarding the use of the software. I wanted to
explain why we did this.</p>

<p>The Democratic Party initially released <a href="https://github.com/democrats/voter-registration">the source code to its online voter
registration app</a> late last summer, with the intent of making it
available for all the standard reasons people and organizations choose when
they open-source code: so that it can be improved, so that bugs can be fixed,
so others can take it and build further new applications on top of it.</p>

<p>However, it was quickly apparent we had a problem with the open source
community. <a href="https://github.com/democrats/voter-registration/issues/12">The issue was with the license</a>. It contained a clause that
placed restrictions on its use. The reason this clause was included was to
address our concerns regarding the highly regulated and closely monitored
nature of voting and voter registration. We wanted to avoid a scenario where,
either inadvertently or through malice, someone set up a site based on the
code, and without following state and federal guidelines and rules, defrauded
or disenfranchised a voter. Now, regardless of our good intentions on this
matter, the fact that we had taken a standard open source license and amended
it with this restrictive clause meant that we did not pass “free and open
source” muster, with emphasis on the “free” as in “speech”.</p>

<p>We needed a solution that addressed both the problematic license and our
concerns regarding the good-faith use of the software that protected voters. A
member of the open source community, <a href="http://www.red-bean.com/kfogel/">Karl Fogel</a>, stepped forward
with a proposal: change the license to an unmodified standard
<a href="http://opensource.org/licenses/index.html">OSI</a>-approved license, and include along with the source code an
advisory document that outline these legal concerns. The notice would not be
binding or otherwise modify the license and therefore terms of use; however,
like any piece of open source software, people are “free” to use it illegally,
and free to suffer the consequences if they do. The important thing is to
remind users of their responsibility to act in accordance with the law,
especially when it comes to something as precious and beseiged as our
franchise. We feel the combination of a standard FOSS license and a
non-binding advisory document expressing the intent of the copyright holder is
a way forward for political organizations to release potentially sensitive
soure code while at the same time communicating the vital issues animating and
conditioning that release.</p>

<p>Now, some observers may not see this as remarkable. There was a bad license,
it’s been changed, what’s the fuss? I want to acknowledge the hard work across
the organization, from software engineers to lawyers, to find a way to give
back to the open source community and satisfy the concerns of both. There are
many reasons why organizations don’t release their software as open source. We
want to set an example, however small, that there are non-license ways to
state any reservations or guiding principles your organization that ordinarily
would have prevented a release. Key among these are engaging with the
community. As we have learned time and again, good solutions often originate
through trust and dialogue.</p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2013/01/lexing-oscar.html" title="Permalink to this post">Lexing Oscar</a></h1>
    <time datetime="2013-01-11" pubdate>January 11, 2013</time>
  </header>
  <p>For the past <em>n</em> years, I’ve built and hosted a web app that lets my film
buff friends and me compete by guessing who will win the Academy Awards by
voting for nominees in each category. I do a new one from scratch each time.
It’s a fun diversion, but it’s also a playground for me to try out new
skills picked up in the past year or new tools or techniques I’ve been wanting
to fool around with.</p>

<p>The first thing I need to do each time is get a list of that year’s nominees
in some machine-readable format. Being a lazy programmer, I’m not going to
type in the 100+ nominees into a spreadsheet or text file, so I wind up
writing a short throwaway script to coax some list I’ve found online into the
form I need for importing. This sort of script is the meat-and-potatoes of the
workaday programmer, the ones you whip up in a few minutes as an intermediate
step in a larger task. Ordinarily, they’re hardly worth commenting on. They
have a vanishingly short half-life, since there is rarely any generality to be
derived from them: they only work on the exact input given.</p>

<p>This year, I wanted to try out a new way of getting the nominee list together.
Sure, for a small task like this, there’s no compelling reason not to go with
the same kind of quick throwaway script as before. But again, the point of the
Oscars app is to exercise new or different muscles.</p>

<p>My goal was to generate a representation of the list of nominees in a format
such as CSV suitable for importing into a database. I found a source list of
nominees, formatted as follows: the name of the category is on the first line,
then a list of nominees comes next, each requiring two lines, one being the
name of the film and the other a name or list of names associated with the
nomination, all followed by a blank line, then the subsequent category starts
on the next line and we repeat. I wanted to read in and parse text formatted
like this:</p>

<pre><code>Directing
Amour
Michael Haneke
Beasts Of The Southern Wild
Benh Zeitlin
Life Of Pi
Ang Lee
Lincoln
Steven Spielberg
Silver Linings Playbook
David O. Russell

Actor in a Leading Role
Lincoln
Daniel Day-Lewis
…
</code></pre>

<p>And convert it to this:</p>

<pre><code>Directing,Amour,Michael Haneke
Directing,Beasts Of The Southern Wild,Benh Zeitlin
Directing,Life Of Pi,Ang Lee
Directing,Lincoln,Steven Spielberg
Directing,Silver Linings Playbook,David O. Russell
Actor in a Leading Role,Lincoln,Daniel Day-Lewis
</code></pre>

<p>Normally, to scan and parse this type of input, I would write a program to
loop over each line of the input, with a number of global state variables,
keeping track of what tokens I was currently processing. In this case, I might
have global state variables indicating whether I was currently processing a
category and what the current film is, and I would have a set of if/elif/else
statements for tests of various combinations of those variables, including for
the contents of the current line (a blank line or EOF indicating the end of a
category).</p>

<p>Each time through the loop, then, we get a line from the text and check to see
what state we’re in. While this approach is easy to get started with, it leads
to fragile code and requires a lot of mental bookkeeping. Worse, each time
through the loop, the state of where we are and what we just did is forgotten.
That accounts for the proliferation of state variables to be checked in order
to restore the state of the processing.  Think about it, we are marching
sequentially through this text, wouldn&#39;t it be nice if we could just pick up
where we left off with the last action?</p>

<p>My approach this time is inspired by <a href="http://www.youtube.com/watch?v=HxaD_trXwRE" title="Lexical Scanning in Go - Rob Pike">Rob Pike’s talk on lexical scanning</a>.
Instead of a loop where we get the next bit of text to examine and restore the
state of the processing by examing a number of state variables, we instead
have a loop where a function is called that returns the next function to be
called. In other words, a function is called which does a bit of processing of
the text, advancing the pointer or consuming from a stream, maybe emitting
some tokens, and then returns to the caller the function that should proceed
from where the returning function just left off. For instance, we just scanned
a category, which means we know we are ready to scan a film, so call the film
scan function. That next function can just carry on its processing without any
state-checking preliminaries. The loop of our system therefore is very
concise, just calling functions and getting the next one to call the
subsequent time around. Roughly:</p>

<pre><code>def run():
    state = start_state
    while state:
        state = state()
</code></pre>

<p>When we are done processing input, say, EOF is reached, the state function
currently executing can return <code>None</code> to the caller, which will end the while
loop and shut down the machine.</p>

<p>The advantage to the programmer is that instead of building up a complicated
switch of control to determine what state our machine is in, we simply write
functions that proceed naturally from the last state, and then hand off
control to the subsequent function. It’s clean and helps keep the complexity
of the system manageable. Any time you can reduce the number of control flow
statements and replace them with simple functions is a win in my book.</p>

<p>So back to the Oscars. This year, I opened the <a href="http://cdn.media.oscar.abc.com/media/2013/pdf/2013/nominees.pdf">official nominee list</a> from
the Academy’s site, a PDF. I selected the text, copied and pasted it into a
text document. The only manual editing I did was to add a blank line between
each group of nominees by category, and I also joined lines in categories like
Music (Original Song) where the title of the song and the name of the composer
is split across multiple lines—these were quick changes that simplified the
scanning logic.</p>

<p>There are three state functions in my program, one for each of category, film,
and name (or list of names):</p>

<pre><code>def lex_category(lexer):
    lexer.emit(CATEGORY, title(getline()))
    return lex_film

def lex_film(lexer):
    line = getline()
    if line == &#39;&#39;:
        lexer.emit(BLANK, &#39;&#39;)
        return lex_category
    elif line is None: # EOF, shut down lex machine
        return None
    lexer.emit(FILM, title(line))
    return lex_names

def lex_names(lexer):
    lexer.emit(NAMES, title(getline()))
    return lex_film
</code></pre>

<p>(<code>title()</code> handles some odd case formatting in the source text by converting
strings to title case.)</p>

<p><code>lex_film</code> is the most complex, having to handle the possibilities of a blank
line, meaning we’re moving on to the next category, EOF, which shuts down
scanning, and the film itself. But in all cases we merely return the next
state function to called (or <code>None</code>).</p>

<p>Admittedly, this is more sophistication than normally appears in my yearly
nominee list parsing. But I have to say that I was able to write the program
in about the same amount of time, found it ran correctly the first time, and
was actually kind of fun to do. And while this was a silly example, you can
start to see the power you can get from this approach when lexing different
kinds of input with more and more complex tokens. When you lift the flow of
control up a level and let your functions focus on the task at hand, the
result I think is a more elegant and more obviously correct program.</p>

<p>The script and input text are <a href="https://gist.github.com/4507999">here</a>, and the output list of nominees is
<a href="https://docs.google.com/spreadsheet/ccc?key=0AviXLd8uXec3dHRtenJGcUs5aTBXUEY4cWs2WHNpS3c#gid=0">here</a>.</p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2012/08/the-election-day-advent-calendar.html" title="Permalink to this post">The Election Day Advent Calendar</a></h1>
    <time datetime="2012-08-07" pubdate>August 07, 2012</time>
  </header>
  <p style="float: right; margin: 0 0 10px 10px"><a href="http://www.kickstarter.com/projects/electioncalendar/the-election-day-advent-calendar" title="The Kickstarter for the Election Day Advent Calendar"><img src="/images/edac2012.jpg" alt="The Election Day Advent Calendar"></a></p>

<p>My friend Ben Helphand and I started scheming in 2005 on a way to
celebrate the right to vote. We believed that a great nation deserves
great civic rituals, and the election season was the natural time for
such a ritual. What we came up with was <a href="http://electioncalendar.net/2006/">the Election Day Advent
Calendar for 2006</a>. The idea was simple: inspired by the
traditional Advent calendar for Christmas, our calendar let you open a
door a day through Election Day, and reveal interesting facts and quotes
about our democracy and the history of voting. It would be non-partisan
but not scrubbed of parties, a reflection on the many events and people
that comprise the story of the franchise.</p>

<p>We wanted to make a real calendar that you could buy and hang up.
Neither of us had any experience in the print production world, and we
both had day jobs in different fields. We had to figure out all the
steps of the process, from hiring an artist to forming an LLC to sales
and shipping and marketing. We put up our own money to fund it, and
hoped to sell enough just to break even.</p>

<p>The response to that first Calendar was strong, and told us there was a
desire for such products that let us all celebrate the shared history of
American politics. People were delighted by the concept; when they saw
it, they got it. We heard from teachers that it made a great part of
their back-to-school civics lesson plans, and from many people who said
they gave it out as a gift to a politics-nerd friend or colleague.</p>

<p>After repeating the process in <a href="http://electioncalendar.net/2008/">2008</a>, we took a break in 2010 but
didn’t give up on the core idea. What we needed, though, was a different
approach to paying for production—it was just too risky to put up our
own money time and again. In the meantime, along came Kickstarter. It’s
perfect for a project like ours.</p>

<p>As I write, there are 6 days remaining in our campaign, and we’re a
little more than half way to our goal. If you’re reading these words and
like what I’ve described, <strong><a href="http://www.kickstarter.com/projects/electioncalendar/the-election-day-advent-calendar">please support our Kickstarter</a></strong>.</p>

<p>Our motto with Gerrymander, the small company Ben and I founded for the
Calendar, is “Make Small Plans”. It’s a gently mocking riff on Daniel
Burnham’s famous and possibly apocryphal <a href="http://www.ontko.com/pub/rayo/burnham.html">quote</a>. Our republic,
as great and large as it is, is still composed of the small democratic
actions of all of us, and those things require care and feeding, and
they ask to be done well. If the Election Day Advent Calendar provides
civic nourishment in any way, then it will have been a success.</p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2012/03/migurski.html" title="Permalink to this post">Interview: Mike Migurski</a></h1>
    <time datetime="2012-03-30" pubdate>March 30, 2012</time>
  </header>
  <style>
  dt {
    float: left;
    font-weight: bold;
    margin-right: 0.25em;
  }
  dt:after {
    content: ":";
  }
  dd {
    margin: 0 0 1em 0;
    padding: 0;
  }
  .q + dd {
    font-weight: bold;
  }
  #map {
    height: 350px;
    width: 100%;
    border: none;
  }
</style>
<iframe id="map" src=
"http://maps.stamen.com/watercolor/embed#13/40.4404/-79.9928"
name="map"></iframe>

<p><a href="http://mike.teczno.com/">Mike Migurski</a> is partner
and Director of Technology at <a href=
"http://stamen.com">Stamen</a> design studio in San Francisco. He
and his Stamen colleagues recently unveiled a new site, <a href=
"http://maps.stamen.com/">maps.stamen.com</a>, that included
three custom-rendered maps using data from <a href=
"http://openstreetmap.org/">OpenStreetMap</a>, including a
remarkable one that, despite being generated by algorithm from
precise vector data, resembled a hand-made watercolor
painting.</p>

<dl>
  <dt class="q">Paul Smith</dt>

  <dd>
    <p>You’ve blogged about the process of creating the Terrain
    map tiles, and the code for the Toner tiles is open-sourced and on
    GitHub, but the Watercolor tiles seemed to come out of the
    blue. Can you talk about what inspired them, how you and your
    Stamen colleagues went about designing them, and what uses
    you imagined for them?</p>
  </dd>

  <dt>Mike Migurski</dt>

  <dd>
    <p>The main use we imagined for them was that they would look
    really, really good, and unlike anything else being done with
    online maps. The process started with Eric Rodenbeck and Zach
    Watson kicking around some ideas on simulating the appearance
    of watercolor painting algorithmically, and expanded to
    include <a href=
    "http://www.flickr.com/photos/sensescape/sets/72157629121886440/">
    Geraldine Sarmiento’s hand-done textures</a>.</p>

    <p>We saw an amazing reaction to <a href=
    "http://www.20x200.com/blog/2011/11/aaron-straup-copes-prettymaps-across-the-us-of-a.html">
    Aaron Straup Cope’s work on Prettymaps</a> last year, and
    more generally a lot of interest in map-based art, so it
    seemed natural to try something that was algorithmic and at
    the same time had the appearance of being made by hand. I
    figured people would swallow their tongues in surprise when
    they saw these, especially when we switched from image search
    results for painted textures to pictures we were making
    ourselves for the project.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>Making maps these days is often about mechanizing the
    conversion of vector data, like from <abbr title=
    "OpenStreetMap">OSM</abbr>, into raster images, which has
    meant perfecting our ability to layer and style points,
    lines, and polygons in very precise ways. I think what
    captivated people about the Watercolor tiles is that they
    seemed to color outside the lines, so to speak, in a way that
    didn’t seem possible with current tools. What tools did you
    use to generate the tiles, and how did you engineer them in a
    way to achieve this effect? Did you have to write new
    software to aid you?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>We did write new software, yes. We’ve been exploring ways
    to make <abbr title="OpenStreetMap">OSM</abbr> data more
    usable by cartographers over the past few years, and that’s
    largely been expressed in code designed to make large data
    sets easier for cartographers (and ourselves) to deal
    with:</p>

    <ul>
      <li>
        <a href=
        "http://mike.teczno.com/notes/cascadenik.html">Cascadenik</a>
        was the first widespread application of CSS-like style
        rules in this area, since developed and expanded by
        Development Seed in Carto.
      </li>

      <li>
        <a href="http://tilestache.org/">TileStache</a> is a
        tile-generation server built to deploy custom
        visualization and rendering code.
      </li>
    </ul>

    <aside class="pull">I figured people would swallow their tongues in
    suprise when they saw these.</aside>

    <p>I’ve been talking about this stuff for a few years, and
    the release of <a href=
    "http://maps.stamen.com/">maps.stamen.com</a> is intended to
    be a showcase that helps shift expectations of what good,
    online cartography should look like. It hasn’t been long
    since using a solid anti-aliased vector-rendering library
    like Mapnik was enough to make a strong showing against
    commercial map providers, but now we’re starting to establish
    new ideas around texture, color and labeling that require a
    layer of additional work beyond Mapnik.</p>

    <p>Watercolor itself is a custom Provider to TileStache,
    feeding on simple Mapnik output and adding techniques like
    gaussian blur and Perlin noise as well as high-quality scans
    of actual water color paintings to achieve its effect. The
    development of watercolor had a number of stages, beginning
    with Zach’s experiments in noise and texture, Eric and George
    Oates’s encouragement, Geraldine’s addition of color and
    texture, and proceeding to my work with Jeff Easter and
    Nathaniel Kelso to improve performance until the code was
    good enough for public launch. The visual appearance is
    ridiculously CPU-hungry compared to your typical vector
    cartography, so we’ve got a few virtual servers on the moon
    doing the live calculation of new maps in new places.</p>

    <p>Without diving too deeply into the actual watercolor code,
    we owe a lot to <a href=
    "http://www.mprove.de/script/90/KPT/index.html">Kai Krause’s
    Algorithmic Painting</a> ideas from almost 20 years ago.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>I see that Stamen is releasing these tiles under a
    Creative Commons license as part of a Knight
    Foundation-funded project centered around data visualization
    and cities. City governments are historically big users of
    enterprise GIS software like ArcGIS; are there any lessons
    here for government or citizens, or does the work,
    specifically the Watercolor tiles, speak for themselves as
    art?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>I think the latter: watercolor is basically art. Of course
    there’s an undeniable political component to the
    OpenStreetMap data it’s made of. In the U.S. <abbr title=
    "OpenStreetMap">OSM</abbr> Foundation we’re interested in
    ways to get government at various levels to participate
    custodians of <abbr title="OpenStreetMap">OSM</abbr>, and I
    think open data and enterprise GIS software can cooperate.
    Esri puts a lot of effort into OpenStreetMap-related efforts,
    and I’m not expecting to see their involvement in city
    governments wane.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>Can you expand a bit on the interplay of vector data,
    raster data, and image filters to produce the tiles? What
    sort of preliminary work did you need to do to get the
    components parts to fall into place? Do you see patterns
    emerging and opportunities for abstraction for future artist
    map tools?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>I probably can’t explain as well as <a href=
    "http://content.stamen.com/watercolor_process">Zach just
    did</a>.</p>

    <p>As a bystander to this part of the process, it seemed like
    the actual simulation technique took shape in just a few
    days, based on Zach’s existing experience with image
    manipulation in Python. The real work came in the
    knob-twiddling, or as we call it internally, “spring tuning”
    (based on our experience with the Digg Swarm project from
    2007). <a href=
    "http://content.stamen.com/files/noise%20v%20threshold.jpg">Here,
    for example, is one of Zach’s own parameter views</a> that he
    used to tune noise thresholds for the ground texture.</p>

    <aside class="pull">It’s intended to shift expectations of what
    good, online cartography should look like.</aside>

    <p>I think the pattern that’s emerging for me is the raw
    labor-intensivity of this kind of work, the
    parameter-tweaking in a space of possible outcomes that
    results in something that looks right and feels exciting.
    Once the basic structure of noise, blur and threshold is in
    place, all you can really do is watch carefully as you
    repeatedly try combinations until something clicks.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>We’re usually talking about algorithms and stylesheets
    when we talk about web maps. Traditional cartographers often
    exercise artistic license over data streams as well—for
    example, manually but subtlety tweaking the curve of a road
    so that it reflects a shared or colloquial understanding of
    its location rather than it’s literal location. And then
    there are the more abstract but functional examples like
    subway system maps, whose stops and lines are not intended to
    be scale representations of their real-world counterparts. Do
    you see it possible for automated cartography to produce maps
    like these? What techniques would we need to develop (for
    example, a “hints” file ala typography for manually
    overriding certain points)?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>I’ve not yet seen an attempt at automating this kind of
    cartography which has resulted in a satisfying outcome, but
    it’s still the subject of many PhD theses, so maybe it’s just
    too early. I suspect that we’ll end up seeing is a companion
    project to <abbr title="OpenStreetMap">OSM</abbr> where human
    make decisions about how things should be shown and
    contribute those to a free and open data source. Everything
    is still so manual in this world, and the subject of most
    maps doesn’t move around all that much, so you can really
    apply a human eye to get it right. Even with the watercolors,
    we had to do a lot of manual work to ensure that the
    1024×1024 watercolor texture blended cleanly and the various
    road sizes looked correct at each zoom level.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>Regarding deployment. One of the challenges of producing
    raster map tiles for the web is the amount of storage and CPU
    time it takes to generate them; I notice that Stamen’s tiles
    are available down to zoom 18, which for a worldwide set
    means there are millions and millions of individual PNG
    files. To a degree CPU time can be amortized over the life of
    the project if you’re using a tile server to dynamically
    generate and cache tiles as users first request them, but
    even with commodity storage like S3, you’re talking about
    hundreds of GB or more. Are there knock-on challenges this
    presents for deployment and maintenance? Is there a
    sustainability plan for maps.stamen.com with regard to
    storage and bandwidth costs, or is Stamen as a company just
    going to eat those costs to provide this resource?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>We’re using a mix of physical and virtual machines for
    each of the tile sets we just released, blending the
    strengths and weaknesses of each. The CPU-intensive rendering
    of watercolor maps is done on Amazon EC2 where we can invoke
    extra machines as necessary, but the PostGIS, Mapnik and
    cache storage parts are all living on an actual server in a
    colocation facility. We decided last year to invest in
    physical hardware to take advantage of the high random-access
    speed of solid state disks, which make it possible to serve
    the entire OpenStreetMap planet database without incurring
    the overhead of Amazon’s terribly slow I/O speeds.</p>

    <p>Fortunately, the back-end of this project is used to drive
    a lot of our other work, so we’re folding the cost into a
    series of different engagements that all use different
    components of the map tiles.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>We appear to be reaching a tipping point where rolling
    your own custom map stack seems not only practical but
    desirable for many applications. What is your reaction to the
    embrace of <abbr title="OpenStreetMap">OSM</abbr> by
    prominent technology companies, and the emergence of
    designer-friendly tools like TileMill? Do we have everything
    we need for most designers and developers to create the map
    experiences they want to provide? What tools would you’d like
    to see built; what data sets made available?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>Honestly, I’m completely thrilled. With this year’s
    high-profile addition of Foursquare and Apple to the
    OpenStreetMap community, I’m looking forward to seeing what
    new artists and designers decide to do with maps—I can’t
    wait for the U.S. State Of The Map conference this
    autumn.</p>

    <aside class="pull">Bitmap tiles have an equilibrium of performance,
    size and design that I don’t think will be disturbed any time
    soon.</aside>

    <p>I think there are two issues that current tools don’t
    address well enough, and I’m excited to be working on them
    both: medium-scale data for counties and towns, and more
    options for bitmap filtering and output. I want Photoshop and
    Illustrator in the sky, essentially, and tools like TileMill
    help expose places where we need to be doing more with data
    before rendering and more with pixels after rendering.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>Elaborate on what you mean by “medium-scale data”, and how
    it would improve map-making.</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>My colleague Nathaniel Kelso runs a project called
    <a href="http://www.naturalearthdata.com/downloads/">Natural
    Earth Data</a>, which offers global vector data at three
    different scales, optimized for rendering images of large
    regions, countries and continents, up to about zoom=9 if you
    think in terms of web slippy maps. OpenStreetMap meanwhile
    offers small-scale data down to the level of individual
    carriageways on major streets. There’s a gap between these
    two data sets where <abbr title="OpenStreetMap">OSM</abbr> is
    too detailed and Natural Earth is not detailed enough, so on
    many renderings you get bizarre selections of town names to
    render, doubled-up street names, or no global context.</p>

    <p>The <a href="http://maps.stamen.com/#terrain">Terrain
    layer on maps.stamen.com</a> is a vehicle for exploring a few
    avenues through this problem: feature generalization for
    route shields and large street names using the <a href=
    "http://github.com/migurski/Skeletron">Skeletron</a> library,
    simulated annealing for smarter label placement with <a href=
    "https://github.com/migurski/Dymo">Dymo</a>, and <a href=
    "https://github.com/migurski/DEM-Tools">cross-blending of
    raster data sets for ground cover and hill shading</a>. We’re
    doing a lot of work to make <abbr title=
    "OpenStreetMap">OSM</abbr> data better for rendering, and
    releasing all the component parts as software for processing
    data sets.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>Do you see Mapnik as the appropriate place to grow the
    bitmap filtering and output functions?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>As far as Mapnik’s role in all this, I think it’s the
    single best place to do vector rendering, but I’m looking
    elsewhere for filtering and output. I prefer to use tools
    that are specialized for individual tasks, so we use the
    pixel output of Mapnik as a source for Python-based pixel
    manipulation code, often implemented in libraries like NumPy
    that offer rapid manipulation of bitmap arrays.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>It sounds like you’re hinting at a new program for this
    kind of manipulation. You and Stamen have contributed a great
    deal of open-source map making software over the years; will
    the code that created Watercolors be released?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>I hope I’m not sounding too coy; there’s not any secret
    piece of software running the show, just a set of well-known
    techniques in a new arrangement. I’ve released everything
    I’ve ever started, but my role in Watercolor was more about
    taking something that already worked and making it work a
    little better so more people could see it.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>Most web maps are a pre-baked set of raster images
    assembled in the viewport of the browser—do you see this
    fundamental arrangement changing in the foreseeable future?
    With WebGL and HTML5 Canvas, are we ready to composite maps
    client-side with servers pushing vectors data over the wire?
    What tradeoffs are there here? Do you think you could do
    Watercolors entirely in the browser anytime soon?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>I don’t think we’re far off, though there are a few
    impediments still in the way. Much of the core functionality
    of Watercolor’s bitmap effects can be implemented entirely on
    a GPU in a WebGL fragment shader, so there’s no reason that
    we couldn’t build it that way. As far as shipping vectors,
    I’d love to see it happen. It’s actually not unrelated to the
    work we’re doing with differently-scaled data: you want your
    underlying data to be at the “right” level of complexity, and
    that generally means modifying it in some way, by dropping
    extra points, scrunching narrow polygons into lines, making
    small things disappear, and lumping groups of things together
    into single blobs. If we can figure out a better way to
    simplify on the fly, then complete client-side rendering
    could be a reality. Of course, Google has already done a lot
    of this themselves, but it’s different when the open source
    community does it and shares the results and the
    research.</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>Simplification of lines and polygons is a common need for
    mapping projects, not only for display but also for
    interaction—clients can only handle so many points during the
    refresh cycle. It can be a big challenge for workflows to
    simplify vectors, and also to preserve topology, the
    relationship between shapes—our model is of disconnected
    points, lines, and polygons. That’s one reason I’m excited
    about topology as a type coming in PostGIS 2.0. What
    simplification techniques should we be using and exploring,
    both on the algorithm side as well as the workflow side?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>I spent about two years (off and on) researching line
    generalization. Skeletron went through three iterations,
    starting with a port of the straight skeleton technique from
    <a href="http://teczno.com/s/vkp">Tom Kelly’s
    description</a>, to a collaboration with Schuyler Erle
    binding to the <a href="http://teczno.com/s/vlv">CGAL library
    from Python</a>, finally settling on an application of the
    <a href="http://teczno.com/s/2trs">Voronoi diagram first
    published by Esri</a> in 1996. All the way through, I kept
    thinking that there just had to be an easier way to make
    simple lines out of complex ones, and why wasn’t I finding
    code to do it for me? The simplification techniques we should
    explore are all known and published, but exist largely as
    plugins for systems like ArcGIS, instead of chainable tools
    in the Unix style. PostGIS 2.0 is going to help in a big way,
    and I hope that some of that effort migrates out to tools for
    managing workflows around flat files.</p>

    <aside class="pull">All you can really do is watch carefully as you
    repeatedly try combinations until something clicks.</aside>

    <p>If all goes well, it should start to make sense to ship
    vectors over the wire and render them on the client.</p>

    <p>It’s an interesting question to me whether client-side
    rendering really something we want to aim for, though. Bitmap
    tiles have an equilibrium of performance, size and design
    that I don’t think will be disturbed any time soon. I’m
    learning what I can about GPUs to be ready when the day
    comes, but in the meantime most of my focus is on developing
    workflows for data. <abbr title="OpenStreetMap">OSM</abbr>
    extracts are one aspect of this; simplifying <abbr title=
    "OpenStreetMap">OSM</abbr> data and standing up fresh new
    rendering databases from source data is another. The
    scaffolding that makes life easiest is a combination of bias
    toward flat files and Postel’s Law: don’t screw around with
    “seamless” servers, publish data flat using old file formats,
    and only invent brand new things when they’re needed.
    Spherical Mercator slippy map tiles are fast becoming one of
    those well-understood old file formats, so this is what we’ve
    aimed for with Watercolor; otherwise, how could we have a
    section on maps.stamen.com showing how to use the imagery in
    your own applications?</p>
  </dd>

  <dt class="q">PS</dt>

  <dd>
    <p>That’s interesting—so are you generally fine with the way
    Spherical Mercator has colonized the web map world? It seems
    to have been a decision purely about tradeoffs: what
    projection “works” for world-wide maps all the way down to
    zoom level 22, or however detailed Google Maps gets these
    days. But clearly choice of projection is a never-ending
    debate. Is Spherical Mercator an acceptable enough
    constraint, from your perspective, within which to do the
    kind of artistic expression Stamen does, and maintain
    interoperability?</p>
  </dd>

  <dt>MM</dt>

  <dd>
    <p>Oh yeah, I’m absolutely fine with it. It’s one of those
    “assume a spherical chicken” engineering solutions that
    actually leads to so much follow-on innovation that in
    retrospect I’m glad no one was letting the cartographers
    drive at Google in 2005. Projections only matter when you’re
    looking at large areas, and that’s really not the case when
    you’re searching for driving directions or checking out the
    neighborhood where you spent elementary school. It’s
    interesting to me, though, that the typical fifty states map
    you see on every link bait infographic out there is based on
    a conic projection—it’s about what looks right for a genre of
    mapmaking, and in the case of slippy maps the Spherical
    Mercator is clearly the obvious choice.</p>
  </dd>
</dl>

<p>—<a href="http://twitter.com/paulsmith" title="Follow me on Twitter">@paulsmith</a></p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2011/09/dnc.html" title="Permalink to this post">Going to work for Democrats</a></h1>
    <time datetime="2011-09-04" pubdate>September 04, 2011</time>
  </header>
  <p><img src="/images/eb-to-dnc.png" style="display: block; float: right; margin-left: 15px"></p>

<p>I have some exciting news: in a couple of weeks, I will be the new deputy
director of technology at the <a href="http://www.democrats.org/">Democratic National Committee</a>. I’ll
be helping to create software that helps get Democrats elected. It’s
a great opportunity for me to do what I love for an organization that I
passionately support. I hope to help make the technology department there
top-notch in terms of software engineering practices, bringing what I’ve
learned from having helped develop, deploy, and grow <a href="http://www.everyblock.com/">EveryBlock</a>. And
I’ll have some projects of my own, which will hopefully advance the
state of campaign software somewhat. It’s especially exciting, too, to
be able to collaborate with <a href="http://twitter.com/harper">friends</a> <a href="http://twitter.com/detour1999">in</a> <a href="http://twitter.com/gabaug">Chicago</a>
<a href="http://twitter.com/scottvdp">working</a> <a href="http://twitter.com/aconbere">on</a> <a href="http://www.barackobama.com/">that one campaign</a>.</p>

<p>I have been volunteering on political campaigns—federal, state, and
local races—for years, and have often lamented the state of campaign
software. It’s partly understandable, because campaigns tend to be
all-hands-on-deck, hair-on-fire affairs, where it’s hard to justify
long-range planning and software development, even if it might make
the lives of your staff, organizers and volunteers easier, since your
organization may not even exist for more than a few months. And campaigns
rarely have in-house software engineers, so opportunities to capture and
encode knowledge in the form of software, and explore new technologies,
are missed.</p>

<p>Obama For America gets this—that’s why they’ve hired like a start-up
for this campaign cycle, recognizing that great software is a competitive
advantage and no longer an afterthought you contract out for. And the DNC
gets it, too, and that’s why I’m excited to join them. The chance to
help re-elect this president, restore Democratic majorities in Congress,
and also to help down-ballot Democrats across the country in this and
future campaign cycles is one I couldn’t pass up.</p>

<p>I’ll be commuting to the DNC’s offices in Washington, D.C. from Baltimore
on a regular basis, though I’ll still be working from home a couple of days
each week, so that I won’t too miss much of <a href="/blog/2011/08/maxine.html">this kind of stuff</a>.</p>

<p>It’s a bittersweet development, because I’ll be leaving EveryBlock,
which I helped found 4 years ago. With the success of the <a href="http://blog.everyblock.com/2011/mar/21/redesign/">recent
relaunch</a>, though, I feel now is as good a time as any to step
away. The site is in great hands, and the response from users to the
new version has been enthusiastic. It couldn’t have a better home than
<a href="http://www.msnbc.com/">msnbc.com</a>, who have provided great guidance and resources. I’m
thrilled with the success we’ve had and for how far it’s come, and
I’m confident that it will continue to be the best place on the internet
to help make your block a better place.</p>

<p>I am particularly grateful for having worked with my great EveryBlock
colleagues. I’m humbled by them and their talents and work ethic. It
was a privilege to learn from them and improve my craft, however modestly,
by their examples.</p>

<p>For now, I’m focusing on winding down at EveryBlock, and getting prepared
for a new commute (I’ll try to hack it with the MARC train and a bike)
and a campaign season now fully engaged. It’s a thrilling opportunity,
and I hope to make the most of it.</p>

<p>—<a href="http://twitter.com/paulsmith">@paulsmith</a></p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2011/08/maxine.html" title="Permalink to this post">Maxine</a></h1>
    <time datetime="2011-08-27" pubdate>August 27, 2011</time>
  </header>
  <p><a href="http://www.flickr.com/photos/psmith/6076865981/" title="P1040879.jpg by pauladamsmith, on Flickr"><img src="http://farm7.static.flickr.com/6184/6076865981_a0c284c99a.jpg" width="500" height="334" alt="P1040879.jpg"></a></p>

<p>One month ago today, Maxine Mills Smith arrived in this world. Her mom gave
birth to her at Mercy Medical Center in Baltimore, Maryland, at six in the
morning. She was, and continues to be, a long and strong gal. She enjoys
being carried about and looking up at the changing scenery. Like her father,
she zonks out to the motion of a vehicle ride, be it stroller or car. She
has healthy lungs, likes to exercise them, and is a vocal chirper. She
has been respecting her mom and dad with 5 and 6-hour stretches of sleep
at night, but likes to mix it up from time to time and throw her mom some
napless curveballs. When she is awake, she is bright and alert. Given the
choice, she’d rather have some light assistance and try to stand and
monster march (I said she was strong) than squirm around on her belly like
a beetle.  Her binky is a frequent companion, and she is a champion eater
of mom’s milk.  The doctors and nurses at the pediatrician’s office
think she is doing fine, and give her an extra wink. We think she’s is
doing fine, too. Family love Maxine. Welcome home, my daughter.</p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2011/05/go_time.html" title="Permalink to this post">Parsing and formatting date/time in Go</a></h1>
    <time datetime="2011-05-20" pubdate>May 20, 2011</time>
  </header>
  <p>Go takes an interesting approach to <a href="http://golang.org/pkg/time/">parsing strings to time objects,
and formatting time objects as strings</a>. Instead of using codes like
most languages to represent component parts of a date/time string
representation—like <code>%Y</code> for a 4-digit year like “2011” or <code>%b</code>
for an abbreviated month name like “Feb”—Go uses a mnemonic device:
there is a standard time, which is:</p>

<pre><code>Mon Jan 2 15:04:05 MST 2006  (MST is GMT-0700)
</code></pre>

<p>Or put another way:</p>

<pre><code>01/02 03:04:05PM &#39;06 -0700
</code></pre>

<p>Instead of having to remember or lookup the traditional formatting codes for
functions like <code>strftime</code>, you just count one-two-three-four and each place
in the standard time corresponds to a component of a date/time object (the
<code>Time</code> type in Go): one for day of the month, two for the month, three for
the hour (in 12-hour time), four for the minutes, etc.</p>

<p>The way you put this into action is by putting together the parts of
the standard time in a layout string that matches the format of either
the string representation you want to parse into a <code>Time</code> object or the
opposite direction, when you want to generate a string representation from
an <code>Time</code> object.</p>

<p>Parsing:</p>

<pre><code>package main

import (
    &quot;fmt&quot;
    &quot;time&quot;
)

func main() {
    value  := &quot;Thu, 05/19/11, 10:47PM&quot;
    // Writing down the way the standard time would look like formatted our way
    layout := &quot;Mon, 01/02/06, 03:04PM&quot;
    t, _ := time.Parse(layout, value)
    fmt.Println(t)
}

// =&gt; &quot;Thu May 19 22:47:00 +0000 2011&quot;
</code></pre>

<p>Formatting:</p>

<pre><code>package main

import (
    &quot;fmt&quot;
    &quot;time&quot;
)

func main() {
    t := time.SecondsToLocalTime(1305861602)
    t.ZoneOffset = -4*60*60
    fmt.Println(t.Format(&quot;2006-01-02 15:04:05 -0700&quot;))
}

// =&gt; &quot;2011-05-20 03:20:02 -0400&quot;
</code></pre>

<p>There are predefined constants in the <code>time</code> package for common formats
such as RFCs 822 and 3339.</p>

<p>The use of a mnemonic over obscure formatting codes I think reflects the
pragmatism of Go’s developers and their focus on creating a language
that makes its users more productive. While it is a break with tradition
to abandon <code>strftime</code>-style formatting, they probably recognized that most
developers, no matter how experienced, reach for <code>man strftime</code> or similar
documentation more often than not (hell, I have a mug with the codes printed
on it), and each time they do, it is an expensive context switch, in terms
of lost focus. Writing the standard time down the way yours looks may be
quirky, but it&#39;s easy to recall, and it also happens to match the shape of
your time string, syntatically.</p>

<p>It’s fascinating to see a language with the pedigree of Go—from the
minds of long-time C and Unix developers—toss aside certain old and
venerable ways of doing things. But it’s consistent with a language
that’s relatively small (in the good way of being comprehensible and
coherent), focused on efficiency, and careful in what it includes.</p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2011/04/floppy.html" title="Permalink to this post">A partial list of metaphors, visual and otherwise, anti-skeuomorphism zealots have to tackle to reach utopia</a></h1>
    <time datetime="2011-04-05" pubdate>April 05, 2011</time>
  </header>
  <p><img src="/images/icons.jpg" alt="icons">
Motivated by irrational hatred and overstated claims of the continuing
utility of a 3.5&quot; floppy disk icon to mean “save”:</p>

<ul>
<li>Handset icon, meaning “phone,” on every iPhone, Android</li>
<li>e<strong>mail</strong></li>
<li>Web<strong>site</strong> (implies a physical place)</li>
<li>Wrench or cog icon, meaning “settings” or “preferences”</li>
<li>Shopping cart icon</li>
<li>Clock with analog hands, meaning “time” or time-centric application</li>
<li>Incandescent light bulb, several meanings, including energy settings</li>
<li>Bound, paper book, meaning “book”</li>
</ul>

<p>Of course there are many, many anachronistic interface elements and metaphors
in the world, and <a href="/blog/2010/10/old_things.html">we get by okay</a>. Mainly,
this is because new generations don’t suddenly appear next to us and
start using our computers without any foreknowledge of the metaphorical
items. They spend time learning with the old fogeys for whom information was
sometimes stored inside square pieces of plastic and metal. This overlap is
necessary in general because knowledge about tools is not encoded in our
genetic material. All understanding of <em>use</em> is part of a multi-layered
strata of culture, experience, and relationships.</p>

<p>The real problem anti-floppy-disk people have is explaining a harm,
specifically, a harm that matters. Often when we think of user interface
improvements that matter, we think of examples like improving medical devices
to reduce user error, changes that literally save people’s lives. Or
tweaks to software that improve user efficiency and productivity, saving
money. It’s hard to conceive of what might be improved by finding a better
metaphor for “save” other than some designers’ personal sensibilities.</p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2011/03/redis_get_set.html" title="Permalink to this post">More Redis internals: Tracing a GET & SET</a></h1>
    <time datetime="2011-03-10" pubdate>March 10, 2011</time>
  </header>
  <p>In my <a href="/articles/redis-under-the-hood.html">previous article</a>, I took a
superficial look at how Redis starts up and prepares itself to process
commands. In this article, I&#39;ll follow a <code>GET</code> and a <code>SET</code> command as
they move from client through the server and back. The <code>GET</code> will be for
a key that doesn&#39;t exist, and the <code>SET</code> will set that key.  Then I&#39;ll look
quickly at a subsequent <code>GET</code> and how it differs.</p>

<p>As before, I&#39;m exploring Redis with the source code open in my editor and
indexed with a <code>tags</code> file, and the Redis server running under <code>gdb</code> in
another terminal.</p>

<p>Caveat: this article was written against the codebase of Redis 2.2.1. With
respect to my previous article, for a list of what has changed in Redis since
I wrote it, see this <a href="http://news.ycombinator.com/item?id=2301804">comment on
HN</a>.</p>

<p><strong>Edit:</strong> I made two minor changes based on feedback—Redis keys are not Redis
objects, they are <code>sds</code> strings; and you don’t have to hack the Makefile to
compile without optimizations.</p>

<h1>GET</h1>

<p>Let&#39;s execute the command <code>get users:1234</code> on Redis.</p>

<h2>Preparing</h2>

<p>If you inspect certain variables under <code>gdb</code>, you might not get what you want.
Instead you see a message like &quot;<value temporarily unavailable, due to
optimizations>.&quot; This is because the compiler has optimized the machine code
in such a fashion that the portion of memory you wanted to look at that was
never used, at least for the variable under inspection. To make stepping
through the code and inspecting a little easier, we make sure that Redis is
not compiled with optimizations. You can do this by either building Redis with
the following invocation:</p>

<pre><code>make noopt
</code></pre>

<p>or by setting an environment variable:</p>

<pre><code>OPTIMIZATION= make
</code></pre>

<h2>Sending the command from the client</h2>

<p>If we look at the <code>repl</code> loop of redis-cli, we see that it uses the
<code>linenoise</code> library to split the arguments of the command. It dispatches on
the first argument. The loop checks for client commands that aren&#39;t processed
as a command by the Redis server, like <code>exit</code>/<code>quit</code>, <code>clear</code> (to clear the screen),
and <code>connect</code> (which is a way to connect to a specified Redis server on host
port, instead of the default host of 127.0.0.1 and port of 6379.</p>

<p>Any other argument is considered the name of a command to send to the server.
The remaining arguments are the arugments for that command.</p>

<p>We&#39;re trying to get the on-the-wire representation of the <code>get users:1234</code> command.
redis-cli uses a <code>redisContext</code> struct to encapsulate the state of the
connection to the server, as well as the output buffer where the command in
the form of the Redis protocol is written for sending to the server. We know
from reading the source of hiredis (the Redis C client library that the redis-cli
program is built on) that the <code>obuf</code> field is where the raw command is stored:</p>

<pre><code># hiredis.h:107
/* Context for a connection to Redis */
typedef struct redisContext {
    int fd;
    int flags;
    char *obuf; /* Write buffer */
    int err; /* Error flags, 0 when there is no error */
    char *errstr; /* String representation of error when applicable */

    /* Function set for reply buildup and reply reader */
    redisReplyObjectFunctions *fn;
    void *reader;
} redisContext;
</code></pre>

<p>If we set a breakpoint on <code>cliReadReply</code>, we can inspect the output buffer and
see exactly how the command looks as a bytestring bound for the server.</p>

<pre><code>client $ gdb src/redis-cli
(gdb) b cliReadReply
(gdb) run
Starting program: /home/paul/src/redis-2.2.0-RC2/src/redis-cli 
Reading symbols for shared libraries +. done
redis&gt; get users:1234

Breakpoint 1, cliReadReply (output_raw_strings=0) at redis-cli.c:421
421         if (redisGetReply(context,&amp;_reply) != REDIS_OK) {
(gdb) p context-&gt;obuf 
$1 = 0x100102428 &quot;*2\r\n$3\r\nget\r\n$10\r\nusers:1234\r\n&quot;
</code></pre>

<p>We see that the Redis command <code>get users:1234</code> as entered in our client is
translated to <code>*2\r\n$3\r\nget\r\n$10\r\nusers:1234\r\n</code>. Any Redis client is
going to convert our command expressed in its respective syntax to the same
on-the-wire format. So in Python:</p>

<pre><code>&gt;&gt;&gt; redis_client.get(&#39;users:1234&#39;)
</code></pre>

<p>will send the same <code>*2\r\n$3\r\nget\r\n$10\r\nusers:1234\r\n</code> bytestring to
the server. </p>

<p>Let&#39;s print that bytestring to screen and render those `\r\n&#39;s as line feeds
so we can see an expanded view and get a better look at the protocol.</p>

<pre><code>*2
$3
get
$10
users:1234
</code></pre>

<p>The first bit is <code>*2</code>, which tells us that the arity of the command,
including the command name, is 2. That is, the server should expect two
arguments to follow.</p>

<p>The next bit is <code>$3</code>, which means that the length of the first argument in
bytes is 3. The argument itself follows, our command name, <code>get</code>.</p>

<p>The next bit after that is <code>$10</code>, so the length in bytes of the second
argument is 10. Our one and only argument to the command is next,
<code>users:1234</code>, the key we are trying to <code>get</code>.</p>

<h2>Receiving the command on the server</h2>

<p>If you remember from the last article, <code>readQueryFromClient</code> is a good place
to set a breakpoint in your debugger on the server side for inspecting an
inbound client command.</p>

<pre><code>server $ gdb src/redis-server
(gdb) b readQueryFromClient
Breakpoint 1 at 0x100011445: file networking.c, line 882.
(gdb) run redis.conf
Starting program: /home/paul/src/redis-2.2.0-RC2/src/redis-server redis.conf
Reading symbols for shared libraries +. done
[63700] 01 Mar 11:04:40 * Server started, Redis version 2.2.1
[63700] 01 Mar 11:04:40 * The server is now ready to accept connections on port 6379
</code></pre>

<p>Now back in the terminal with the client running in the debugger, continue to
send the command to the server, which will stop at the breakpoint we set.</p>

<pre><code># client
(gdb) c
Continuing.

# server
Breakpoint 1, readQueryFromClient (el=0x100200000, fd=5, privdata=0x100804e00, mask=1) at networking.c:801
801     void readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) {
</code></pre>

<p>Let&#39;s step to the following line:</p>

<pre><code># src/networking.c:808
nread = read(fd, buf, REDIS_IOBUF_LEN);
</code></pre>

<p>If we step to here in our debugger, we see that the server read 30 bytes. If
you count the number of bytes in our Redis protocol-encoded command,
<code>*2\r\n$3\r\nget\r\n$10\r\nusers:1234\r\n</code>, you&#39;ll see it&#39;s 30. Just for good
measure, let&#39;s look at the 30 bytes beginning at the memory location pointed
to by <code>buf</code>:</p>

<pre><code>(gdb) p nread
30
(gdb) x/30cb buf
0x7fff5fbfeaf0: 42 &#39;*&#39;  50 &#39;2&#39;  13 &#39;\r&#39; 10 &#39;\n&#39; 36 &#39;$&#39;  51 &#39;3&#39;  13 &#39;\r&#39; 10 &#39;\n&#39;
0x7fff5fbfeaf8: 71 &#39;G&#39;  69 &#39;E&#39;  84 &#39;T&#39;  13 &#39;\r&#39; 10 &#39;\n&#39; 36 &#39;$&#39;  49 &#39;1&#39;  48 &#39;0&#39;
0x7fff5fbfeb00: 13 &#39;\r&#39; 10 &#39;\n&#39; 117 &#39;u&#39; 115 &#39;s&#39; 101 &#39;e&#39; 114 &#39;r&#39; 115 &#39;s&#39; 58 &#39;:&#39;
0x7fff5fbfeb08: 49 &#39;1&#39;  50 &#39;2&#39;  51 &#39;3&#39;  52 &#39;4&#39;  13 &#39;\r&#39; 10 &#39;\n&#39;
</code></pre>

<p>And we can see our whole command bytestring is there, byte by byte.</p>

<p>The server has now read in the entirety of our command in one step.  (Because
we had a relatively short command, one that fits inside a kernel buffer, and
we are the only client on a loopback network device, this is the case, but it
need not be. Since Redis is event-driven, this function,
<code>readQueryFromClient</code>, is called whenever there are bytes from buffers to be
read. If our command was particularly long, or there was a lot of network
contention, the command may take more than one I/O event before it is fully
read. For this reason, Redis builds up a buffer per client and appends bytes
to it on each call to this function. It only proceeds with processing the
command when it has been fully read. But we don&#39;t need to consider this in our
simple example, so we will proceed.)</p>

<p>We&#39;re going to elide the processing of the input buffer. This is the point
where the server takes the Redis protocol-encoded bytestring of our request
and unpacks it into arguments on the client struct object. If you are
interested in the details of that parsing, examine the function
<code>processMultibulkBuffer</code> in <code>networking.c</code>. All we are interested in at this
point is that the <code>argc</code> member of the client object is the number of command
arguments (counting the command name itself) and <code>argv</code> is a pointer to the
list of arguments.</p>

<p>The bit of code we care at this point is <code>processCommand</code>. The first thing the
server does is look up the command in its command table (see &quot;Setting up
command table&quot; in the previous article, but note that this lookup is now O(1),
see the HN thread linked above). Assuming the command is found (which our
<code>get</code> will be), the server will double-check that the arity of the command as
defined in the command table matches the number of arguments received from the
client (<code>c-&gt;argc</code>).</p>

<pre><code># redis.c:998
cmd = lookupCommand(c-&gt;argv[0]-&gt;ptr);
if (!cmd) {
    addReplyErrorFormat(c,&quot;unknown command &#39;%s&#39;&quot;,
        (char*)c-&gt;argv[0]-&gt;ptr);
    return REDIS_OK;
} else if ((cmd-&gt;arity &gt; 0 &amp;&amp; cmd-&gt;arity != c-&gt;argc) ||
           (c-&gt;argc &lt; -cmd-&gt;arity)) {
    addReplyErrorFormat(c,&quot;wrong number of arguments for &#39;%s&#39; command&quot;,
        cmd-&gt;name);
    return REDIS_OK;
}
</code></pre>

<p>Skip down to the end of <code>processCommand</code>. Because our humble <code>get</code> is not a
&quot;multi&quot; command like <code>mget</code>, <code>mset</code>, etc., it doesn&#39;t require queue-like
processing of the underlying multiple commands, so we go right to <code>call</code>,
which is where our command is dispatched.</p>

<pre><code># redis.c:953
void call(redisClient *c, struct redisCommand *cmd) {
    long long dirty;

    dirty = server.dirty;
    cmd-&gt;proc(c);
    dirty = server.dirty-dirty;

    if (server.appendonly &amp;&amp; dirty)
        feedAppendOnlyFile(cmd,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc);
    if ((dirty || cmd-&gt;flags &amp; REDIS_CMD_FORCE_REPLICATION) &amp;&amp;
        listLength(server.slaves))
        replicationFeedSlaves(server.slaves,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc);
    if (listLength(server.monitors))
        replicationFeedMonitors(server.monitors,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc);
    server.stat_numcommands++;
}
</code></pre>

<p>Let&#39;s focus on line 952, <code>cmd-&gt;proc(c);</code>. This is Redis&#39;s dynamic dispatching
of command function calling. Redis makes this clean and simple by
encapsulating commands and giving all the actual underlying command functions
the same function signature, taking our client object, which carries the
payload of our command&#39;s arguments. So we&#39;re interested in looking into the
details of the Redis command object and the actual function that will handle
our <code>get</code>.</p>

<pre><code># redis.h:504
struct redisCommand {
    char *name;
    redisCommandProc *proc;
    int arity;
    int flags;
    /* Use a function to determine which keys need to be loaded
     * in the background prior to executing this command. Takes precedence
     * over vm_firstkey and others, ignored when NULL */
    redisVmPreloadProc *vm_preload_proc;
    /* What keys should be loaded in background when calling this command? */
    int vm_firstkey; /* The first argument that&#39;s a key (0 = no keys) */
    int vm_lastkey;  /* THe last argument that&#39;s a key */
    int vm_keystep;  /* The step between first and last key */
};
</code></pre>

<p>If we pop up to the top of <code>redis.c</code>, we see the definition of the Redis command
table, and our <code>get</code> is the first entry.</p>

<pre><code># redis.c:71
struct redisCommand readonlyCommandTable[] = {
    {&quot;get&quot;,getCommand,2,0,NULL,1,1,1},
</code></pre>

<p><code>getCommand</code> is the function that does the actual work for our command.
It&#39;s a thin wrapper for <code>getGenericCommand</code>.</p>

<pre><code># t_string.c:62
int getGenericCommand(redisClient *c) {
    robj *o;

    if ((o = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.nullbulk)) == NULL)
        return REDIS_OK;

    if (o-&gt;type != REDIS_STRING) {
        addReply(c,shared.wrongtypeerr);
        return REDIS_ERR;
    } else {
        addReplyBulk(c,o);
        return REDIS_OK;
    }
}

void getCommand(redisClient *c) {
    getGenericCommand(c);
}
</code></pre>

<p>The arguments to <code>lookupKeyReadOrReply</code> are the client object, the key
<code>users:1234</code> we&#39;re trying to look up, and an object, <code>shared.nullbulk</code> that
will be the default reply to the client if the key is not found.</p>

<pre><code># db.c:58
robj *lookupKeyReadOrReply(redisClient *c, robj *key, robj *reply) {
    robj *o = lookupKeyRead(c-&gt;db, key);
    if (!o) addReply(c,reply);
    return o;
}
</code></pre>

<p><code>lookupKeyRead</code> is a thin wrapper for <code>lookupKey</code> that handles removing keys
that have been set to expire.</p>

<p>Now we get to the heart of the <code>get</code> command -- looking up the key in the
database.</p>

<pre><code># db.c:9
robj *lookupKey(redisDb *db, robj *key) {
    dictEntry *de = dictFind(db-&gt;dict,key-&gt;ptr);
    if (de) {
        robj *val = dictGetEntryVal(de);

        /* Update the access time for the aging algorithm.
         * Don&#39;t do it if we have a saving child, as this will trigger
         * a copy on write madness. */
        if (server.bgsavechildpid == -1 &amp;&amp; server.bgrewritechildpid == -1)
            val-&gt;lru = server.lruclock;

        if (server.vm_enabled) {
            if (val-&gt;storage == REDIS_VM_MEMORY ||
                val-&gt;storage == REDIS_VM_SWAPPING)
            {
                /* If we were swapping the object out, cancel the operation */
                if (val-&gt;storage == REDIS_VM_SWAPPING)
                    vmCancelThreadedIOJob(val);
            } else {
                int notify = (val-&gt;storage == REDIS_VM_LOADING);

                /* Our value was swapped on disk. Bring it at home. */
                redisAssert(val-&gt;type == REDIS_VMPOINTER);
                val = vmLoadObject(val);
                dictGetEntryVal(de) = val;

                /* Clients blocked by the VM subsystem may be waiting for
                 * this key... */
                if (notify) handleClientsBlockedOnSwappedKey(db,key);
            }
        }
        server.stat_keyspace_hits++;
        return val;
    } else {
        server.stat_keyspace_misses++;
        return NULL;
    }
}
</code></pre>

<p>Redis uses its own hash table implementation to store keys and their values in
memory. Inside the <code>db</code> object, the field <code>dict</code> is a pointer to the hash
value for the current Redis database (remember there can be up to 16 separate
databases in a single Redis server instance, indexed by number).</p>

<p>First, Redis calls <code>dictFind</code> with the database&#39;s hash table and a pointer
to the key&#39;s bytestring. <code>dictFind</code> looks up the hash of the key in the
table, using a standard algorithm that should be familiar to anyone who&#39;s
implemented a hash table (check out <code>dict.c</code> starting at line 391 if you&#39;re
interested, the table is an array with linked lists for colliding hashes).</p>

<p>If the key is found in the table, <code>dictFind</code> returns a pointer to the entry in
the table. Otherwise, it returns <code>NULL</code>. Back in <code>lookupKey</code>, if the entry is
not null, Redis retrieves the value (i.e., the Redis object our key
references) from the hash table via <code>dictGetEntryVal</code> and takes care of a bit
of bookkeeping for expiry and VM, if the key was found, and stats in either
case (hits and misses). If the entry was <code>NULL</code>, then <code>lookupKey</code> also returns
<code>NULL</code>; we&#39;ll see how this is handled by Redis for a reply to the client when
the key is not found, which is the case for us at this stage.</p>

<p>With the value of <code>lookupKey</code>, we&#39;ll go back up the stack to our callers. Back
to <code>lookupKeyReadOrReply</code>, we look at line 60:</p>

<pre><code># t_string.c:60
        if (!o) addReply(c,reply);
</code></pre>

<p>Since we got <code>NULL</code> from <code>lookupKey</code> this time, we call <code>addReply</code>.  The value
of <code>reply</code> here comes from the call in <code>getGenericCommand</code>, and it is
<code>shared.nullbulk</code>. This field in the global struct object <code>shared</code> is
initialize thusly:</p>

<pre><code># redis.c:712
shared.nullbulk = createObject(REDIS_STRING,sdsnew(&quot;$-1\r\n&quot;));
</code></pre>

<p>We can see that it is a Redis string object who&#39;s on-the-wire value is
<code>$-1\r\n</code>, meaning a length of -1, Redis&#39;s way of indicating null to a
client, according to the protocol.</p>

<p><code>addReply</code> builds the reply to the client. It does this by first setting up a
write event on the main event loop listener with <code>_installWriteEvent</code>. This
makes sure that the reply is written out to the client connection when there
are bytes present in the buffer. Next, Redis adds the reply to the client&#39;s
buffer. If the reply object were an non-string value like an integer, or a
list, or a set, Redis would first decode it to a bytestring that can be
serialized to, for example, on a socket. Redis string objects are encoded
&quot;raw,&quot; or as-is. The <code>nullbulk</code> object is technically a string object, so no
decoding is necessary in our case. In any case, the reply bytestring is copied
to the client&#39;s reply buffer with <code>_addReplyToBuffer</code>, which for all intents
and purposes completes the execution of our <code>get</code> command on the server.</p>

<p>The client will read the on-the-wire reply of <code>$-1\r\n</code> and know that it is a
string reply of length -1, and therefore is the null (or &quot;nil,&quot; in the context
of <code>redis-cli</code>) object, and to convert that into the appropriate object for
the language of the client. Back to our <code>redis-cli</code> client patiently waiting
for a reply from our breakpointed server, which we continue from, that looks
like:</p>

<pre><code>(nil)
redis&gt;
</code></pre>

<h1>SET</h1>

<p>The <code>set</code> command proceeds much the same way as the <code>get</code>, up to the point of
command dispatching on the server.</p>

<pre><code># client
redis&gt; set users:1234 &quot;Paul Smith&quot;

# server
Breakpoint 1, readQueryFromClient (el=0x100400000, fd=6, privdata=0x100805e00, mask=1) at networking.c:801
801     void readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) {
(gdb) n
802         redisClient *c = (redisClient*) privdata;
(gdb) n
808         nread = read(fd, buf, REDIS_IOBUF_LEN);
(gdb) n
809         if (nread == -1) {
(gdb) print nread
$1 = 47
(gdb) x/47cb buf
0x7fff5fbfeba0: 42 &#39;*&#39;  51 &#39;3&#39;  13 &#39;\r&#39; 10 &#39;\n&#39; 36 &#39;$&#39;  51 &#39;3&#39;  13 &#39;\r&#39; 10 &#39;\n&#39;
0x7fff5fbfeba8: 115 &#39;s&#39; 101 &#39;e&#39; 116 &#39;t&#39; 13 &#39;\r&#39; 10 &#39;\n&#39; 36 &#39;$&#39;  49 &#39;1&#39;  48 &#39;0&#39;
0x7fff5fbfebb0: 13 &#39;\r&#39; 10 &#39;\n&#39; 117 &#39;u&#39; 115 &#39;s&#39; 101 &#39;e&#39; 114 &#39;r&#39; 115 &#39;s&#39; 58 &#39;:&#39;
0x7fff5fbfebb8: 49 &#39;1&#39;  50 &#39;2&#39;  51 &#39;3&#39;  52 &#39;4&#39;  13 &#39;\r&#39; 10 &#39;\n&#39; 36 &#39;$&#39;  49 &#39;1&#39;
0x7fff5fbfebc0: 48 &#39;0&#39;  13 &#39;\r&#39; 10 &#39;\n&#39; 80 &#39;P&#39;  97 &#39;a&#39;  117 &#39;u&#39; 108 &#39;l&#39; 32 &#39; &#39;
0x7fff5fbfebc8: 83 &#39;S&#39;  109 &#39;m&#39; 105 &#39;i&#39; 116 &#39;t&#39; 104 &#39;h&#39; 13 &#39;\r&#39; 10 &#39;\n&#39;
(gdb) print (char *)buf
$2 = 0x7fff5fbfeba0 &quot;*3\r\n$3\r\nset\r\n$10\r\nusers:1234\r\n$10\r\nPaul Smith\r\n&quot;
</code></pre>

<p>This time, our protocol-encoded bytestring is 47 bytes long, owing to the
extra argument &quot;Paul Smith&quot; and the length tag it requires. Also notice the
leading <code>*3</code> indicates there are three arguments: <code>set</code>, <code>users:1234</code>, <code>Paul Smith</code>.</p>

<p>Let&#39;s skip ahead now to the point in <code>call</code> in <code>redis.c</code>, after the command has
been looked-up in the command table and the server is about ready to call the
underlying <code>proc</code> function with the client object argument. The <code>set</code> command,
in the form of a <code>redisCommand</code> struct, looks like this:</p>

<pre><code># redis.c:73
{&quot;set&quot;,setCommand,3,REDIS_CMD_DENYOOM,NULL,0,0,0},
</code></pre>

<p>Notice that the arity of the command is 3, which includes the leading command
name, plus key and value, and matches what we expect from the client. The
<code>set</code> command has a flag that <code>get</code> did not: the constant <code>REDIS_CMD_DENYOOM</code>
means that, in out-of-memory situations where Redis can&#39;t allocate any more
memory, the execution of the command should be denied. (The absence of this
flag means that Redis can continue to serve client &quot;read&quot; requests like <code>get</code>
even when the server can no longer write any new data.)</p>

<p>I set a breakpoint on <code>setCommand</code> and let the server continue running until
that point:</p>

<pre><code># server
(gdb) b setCommand
Breakpoint 2 at 0x10001a6e2: file t_string.c, line 48.
(gdb) c
Continuing.
Breakpoint 2, setCommand (c=0x100805e00) at t_string.c:48
48          c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);
</code></pre>

<p>Incidentally, you can inspect the values of the client&#39;s command arguments at
any time, with a simple <code>gdb</code> invocation. The arguments are of type <code>robj</code>,
which has a field <code>ptr</code> that is a pointer to the actual value in memory. Since
in our <code>set</code> case these are strings, we can inspect them by typecasting to
<code>char *</code> like so:</p>

<pre><code>(gdb) p (char *)c-&gt;argv[0]-&gt;ptr
$10 = 0x10032ae78 &quot;set&quot;
(gdb) p (char *)c-&gt;argv[1]-&gt;ptr
$11 = 0x10032b068 &quot;users:1234&quot;
(gdb) p (char *)c-&gt;argv[2]-&gt;ptr
$12 = 0x10032b098 &quot;Paul Smith&quot;
</code></pre>

<p>The first thing the server does in <code>setCommand</code> is encode the value being set
with <code>tryObjectEncoding</code>. It will try to create an efficient encoding if the
bytestring can be interpreted as an integer, for example. This can save space
especially in the case where many numbers are being stored.  Additionally,
Redis will try to reuse shared integers as values instead of allocating
resources for new ones -- see the previous article for more on the creation
and use of shared integers.</p>

<p>Once the value being set has been encoded, <code>setGenericCommand</code> is called
(<code>set</code> shares <code>setGenericCommand</code> with the <code>setnx</code> and <code>setex</code> commands). From
here, <code>dbAdd</code> is called, with the client, key, and value as arguments. <code>dbAdd</code>
will only add the value to the database&#39;s hash table if the key does not
already exist. In our case, since the key <code>users:1234</code> does not exist, the
value of <code>dictFind</code> is null, and the function proceeds to add the value with
<code>dictAdd</code>.</p>

<p><code>dictAdd</code> takes the dictionary hash table, key, and value as arguments. It
uses <code>_dictKeyIndex</code> to find the index of a free slot in the hash table for
our new entry. See the implementation in <code>dict.c</code> and <code>dict.h</code> for the details
of key hashing, and the structure of the dictionary and its component hash
tables (each Redis dictionary contains two hash tables in order to provide
incremental rehashing as the dictionary grows). <code>dictAdd</code> allocates memory for
the new entry and stores it in the new index.</p>

<p>The server returns back up the stack from <code>dictAdd</code> and <code>dbAdd</code> to
<code>setGenericCommand</code>, where it increments the reference count on our new value.
Redis uses reference counting in order to free memory used by values that have
been deleted or have expired. It then &quot;touches&quot; the key so that if any clients
are <code>watch</code>ing the key, the next <code>exec</code> command will fail. It also increments
the server&#39;s <code>dirty</code> flag, which it uses to determine when to write out the
dump file to disk. Finally, it writes out the reply to the client, which is a
shared object, <code>shared.ok</code>. This is special Redis string object in the
protocol that consists of the bytestring &quot;+OK\r\n&quot;. Clients will typically
convert this into the equivalent &quot;true&quot; value for their language.</p>

<h1>GET redux</h1>

<p>Our key is now set, so we can try the <code>get users:1234</code> command again and see
how it differs for a found key.</p>

<pre><code># db.c:9
robj *lookupKey(redisDb *db, robj *key) {
    dictEntry *de = dictFind(db-&gt;dict,key-&gt;ptr);
    if (de) {
        robj *val = dictGetEntryVal(de);

        // ... skipping the lru &amp; vm parts ... 

        server.stat_keyspace_hits++;
        return val;
</code></pre>

<p>The point where a <code>get</code> on an existing key and a <code>get</code> on a non-existent key
differ is line 11, where the <code>de</code> entry in the database&#39;s dictionary is found.
<code>dictGetEntryVal</code> is a simple macro for accessing the field in the <code>de</code> struct
that carries the value associated with the key. Redis updates its statistics
to indicate a key hit and returns the value object.</p>

<p>Again, as with the key miss from above (remember the null value is a Redis
object, too), the value is decoded into the Redis bytestring protocol. This is
the response to the client, and we have concluded our <code>GET</code>/<code>SET</code>/<code>GET</code> dance.</p>

  </article>
<article class="post">
  <header>
    <h1><a href="/blog/2011/01/bluecollarleague.html" title="Permalink to this post">The All-Blue-Collar League</a></h1>
    <time datetime="2011-01-24" pubdate>January 24, 2011</time>
  </header>
  <p>In honor of the <a href="http://sportsillustrated.cnn.com/football/nfl/gameflash/2011/01/23/4353_recap.html?&amp;eref=sihp">all</a>-<a href="http://sportsillustrated.cnn.com/football/nfl/gameflash/2011/01/23/4354_recap.html?eref=sihp">union</a> Super Bowl, I present the
All-Blue-Collar League, a collection of U.S. professional sports franchises
named after local unions, industry.</p>

<p>In solidarity:</p>

<table id="teams">
    <tr>
        <th>NFL</th>
    </tr>
    <tr class="team packers" title="Named after the Indian Packing Company">
        <td><span></span>Green Bay <b>Packers</b></td>
    </tr>
    <tr class="team steelers" title="Pittsburgh’s economy centered around the steel industry for many years.">
        <td><span></span>Pittsburgh <b>Steelers</b></td>
    </tr>
    <tr class="team cowboys" title="Texas cowboys were freelance livestock herders and handlers.">
        <td><span></span>Dallas <b>Cowboys</b></td>
    </tr>

    <tr>
        <th>MLB</th>
    </tr>
    <tr class="team astros" title="NASA’s Johnson Space Center and the greater space industry is a huge employer in the Houston region.">
        <td><span></span>Houston <b>Astros</b></td>
    </tr>
    <tr class="team brewers" title="Named for the city’s association with the beer brewing industry.">
        <td><span></span>Milwaukee <b>Brewers</b></td>
    </tr>
    <tr class="team mariners" title="The city’s location makes it a natural for many maritime industries, including fishmongering, and fishwivery.">
        <td><span></span>Seattle <b>Mariners</b></td>
    </tr>
    <tr class="team rangers" title="The Texas Rangers have been a statewide law enforcement agency since 1823, the oldest such agency in the U.S.">
        <td><span></span>Texas <b>Rangers</b></td>
    </tr>

    <tr>
        <th>NBA</th>
    </tr>
    <tr class="team pistons" title="Detroit is synonymous with the American auto industry, a source of high-quality middle-class jobs for most of the 20th century.">
        <td><span></span>Detroit <b>Pistons</b></td>
    </tr>

    <tr>
        <th>NHL</th>
    </tr>
    <tr class="team oilers" title="Edmonton is one of Canada’s major oil refinery centers.">
        <td><span></span>Edmonton <b>Oilers</b></td>
    </tr>
</table>

<p>Thanks to <a href="http://twitter.com/kostuch">@kostuch</a>, <a href="http://twitter.com/ikesmith">@ikesmith</a>, <a href="http://twitter.com/joshandrews">@joshandrews</a>, <a href="http://twitter.com/tcarmody">@tcarmody</a>,
<a href="http://twitter.com/lmsahistory">@lmsahistory</a>, and <a href="http://twitter.com/janieporche">@janieporche</a> for suggestions.</p>

<style>
#teams {
    width: 100%;
    margin-bottom: 1em;
}

#teams tr {
    clear: both;
}

#teams th {
    padding: 5px 6px;
}

#teams th {
    background: hsla(215, 35%, 35%, 1.0);
    color: white;
}

#teams td {
    height: 50px;
    line-height: 50px;
    padding: 5px 0;
    border-bottom: 1px solid hsla(215, 35%, 35%, 0.5);
}

#teams td span {
    display: block;
    float: left;
    height: 50px;
    width: 50px;
    margin-right: 10px;
    background-image: url(/images/blue_collar_sprite.png);
    background-repeat: no-repeat;
}

#teams .explanation {
    display: none;
}

.brewers td span { background-position: -50px 0px; }
.cowboys td span { background-position: -100px 0px; }
.mariners td span { background-position: -150px 0px; }
.oilers td span { background-position: -200px 0px; }
.packers td span { background-position: -250px 0px; }
.pistons td span { background-position: -300px 0px; }
.rangers td span { background-position: -350px 0px; }
.steelers td span { background-position: -400px 0px; }
</style>

  </article>

        <aside>
            
<section>
  <p>Blog archive</p>
  <ul>
    <li><a href="/blog/2010/">2010</a></li>
    <li><a href="/blog/2011/">2011</a></li>
    <li><a href="/blog/2012/">2012</a></li>
    <li><a href="/blog/2013/">2013</a></li>
    </ul>
</section>

        </aside>
    </div>
    <footer>
        <p>ⓒ  Paul Smith. This site created with Python.
        <p><em>Always wrong. Never in doubt.</em></p>
    </footer>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.4.4/jquery.min.js"></script>
    <script src="/js/tooltip.js"></script>
    
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-304677-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>
</html>
